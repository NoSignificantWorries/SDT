Задание 1. Линейная регрессия (LinReg) и дисперсионный анализ (ANOVA)
[1] Выбрать один из датасетов из перечня:
- Iris
- Palmer Archipelago (Antarctica) penguin
- Wine Quality
- Любой другой датасет, в котором есть три класса и четыре количественных
(недискретных) признака.
[2] Вывести в табличной форме статистику по датасету, включая
- Размерность всего датасета
- Количество признаков
- Количество целевых классов и объектов в каждом из классов
- Процент объектов с неопределенными признаками
- Иные ключевые характеристики датасета
Выбрать три класса и четыре количественных (недискретных) признака.
Сформировать на их основе «отфильтрованный» датасет для дальнейшего анализа,
удалив из датасета все объекты, для которых не определены значения хотя бы одного из
выбранных четырех количественных признаков.
[3] Выполнить визуализацию датасета по всем парам выбранных количественных
переменных, обозначая:
- в графиках с разными парами переменных объекты из разных классов различными
по форме и цвету точками,
- в графиках с одной и той же парой переменных – гистограммы с достаточным
числом разбиений (обычно – не менее 20), либо плотности распределения
переменной по оси признака.
[4] В табличном варианте оценить степень сопряженности пар признаков-переменных на
всем датасете, используя коэффициенты корреляции Пирсона и Спирмана. В табличном
варианте оценить степень сопряженности пар признаков-переменных в каждом
отдельном классе датасета, используя коэффициенты корреляции Пирсона и Спирмана.
[6] Отдельно повторно выполнить пункт [3]; на каждом из графиков для каждого из
классов отобразить линию линейной регрессии с соответствующими прогнозными
интервалами (predictive bands).
[7] Повторить пункт [5], но с доверительными интервалами регрессий (confidence bands).
[8] Вывести формулы каждой линейной регрессии вместе со значениями критерия R2,
критерия Вальда (F-критерий, его степени свободы и соответствующий p-критерий),
критерия LR (хи-квадрат-критерий, степени свободы и соответствующий p-критерий),
критерия score (хи-квадрат-критерий, степени свободы и соответствующий p-критерий).
[9] Выбрать любой количественный признак и выполнить дисперсионный анализ
(ANOVA):
- Рассчитать F-критерий, его степени свободы и соответствующий ему p-критерий для
всех классов
- Рассчитать апостериорные критерии LSD Фишера для каждой пары классов
- Рассчитать F-критерий, степени свободы и соответствующий ему p-критерий для
каждой пары классов
- Визуализировать выбранный количественный признак для каждого из классов в виде
raincloud plot with jittering, рядом с которым в виде boxplot отображены медианы,
межквартильные размахи (IQR) и доверительные интервалы.
[10] Повторить пункт [9] для каждого из остальных трех признаков.

Задание 2. LDA – линейный дискриминантный анализ.
[1] Используя функцию make_blobs с любым random_state, сгенерировать датасет df1, в
котором есть три класса с размером каждого класса 1000 объектов и 16 количественных
(недискретных) признаков. Распределения двух из трех классов должны значительно
перекрывать друг друга, тогда как третий класс должен быть на расстоянии от первых
двух классов.
# Не забываем повторять шаги задания 1:
- ключевые характеристики датасета

- корреляции
- визуализация на всех парах переменных

[2] На основе созданного в пункте [1] датасета df1 сгенерировать отдельные
дополнительные датасеты (df2, df5, df10…), в которых объекты одного класса (который
имеет пересечение с другим) повторены 2 раза, 5 раз, 10 раз, 20 раз, 50 раз, 100 раз,
1000 раз, 10k раз, а количество объектов в остальных классах осталось неизменно.
[3] Выбрать пару классов (включая класс с повторенными объектами) и пару
количественных признаков. Используя метод LDA (линейный дискриминантный анализ),
для каждого из сформированных датасетов df1, df2, df5, df10, df20, df50, df100, df1000,
df10k, графически построить решающую функцию алгоритма, разграниченные решающей
функцией зоны и отдельные объекты классов; отдельно вывести время построения
решения. # Визуализацию данного пункта лучше реализовать в паре с пунктом [5].
[4] Для датасетов df1, df2, df5, df10, df20, df50, df100, df1000 из пункта [3] восстановить в
таблицу координаты следующих точек:
- центры масс каждого класса;
- общий центр масс выбранных классов;
- центр отрезка, соединяющего центры масс выбранных классов.
Для датасетов отдельно на графиках с решающей функцией LDA вывести положения
центров масс и соединяющий центры масс классов отрезок с его центральной точкой.
[5] Выбрать целевой класс для решений из пункта [3].
Для каждого из решений из пункта [3], оценить качество работы полученных на основе
LDA классификаторов, используя ROC кривые и восстановив на графике ROC кривой
соответствующие решению LDA 95% доверительные полосы (Confidence bands 95%)
ROC кривой бутстрепом (n=1000 или больше). Для каждой кривой численно также
отобразить метрику AUROС (AUC для ROC кривой классификации Sensitivity-Specificity и
ее доверительные интервалы CI95).
# Все полученные графики возможно расположить в две колонки: левая колонка –
визуализация пространства и решений LDA, правая – графики с ROC кривой и
доверительными полосами.
[6] Повторить пункт [5] для PR кривых и отобразить метрику AUPRC (AUC для PR).
[7] В пункте [5] выбрать другой целевой класс и повторить отдельно визуализации ROC
кривых.
[8] Для датасета df10 на основе 3-fold, 5-fold, 10-fold, 20-fold, 50-fold, 100-fold кроссвалидации построить кривые AUROC и AUPRC c 95% доверительными полосами (CI95).
# Вместо CI95 можно взять CI90, CI80 или другой квантиль доверительной полосы.
[9] Для датасета df1 построить решения LDA на двух, четырех, восьми и шестнадцати
признаках. Для каждого решения восстановить по пункту [5] ROC кривые с
доверительными полосами 95%.
[10*] Повторить пункты [3]+[5] для алгоритма SVM.
https://stackoverflow.com/questions/55541254/precision-recall-curve-with-n-fold-cross-validation-showing-standard-deviation
https://stackoverflow.com/questions/29656550/how-to-plot-pr-curve-over-10-folds-of-cross-validation-in-scikit-learn

Задание 3. LogReg.
[1] Используя функцию make_blobs с любым random_state, сгенерировать датасет df, в
котором есть три класса с размером каждого класса 100 объектов и восемь
количественных (недискретных) признаков, при этом центры классов зафиксированы в
следующих точках: Класс 0 – (+1,+1,+1,+1,+1,+1,+1,+1), Класс 1 – (-1,-1,-1,-1,-1,-1,-1,-1),
Класс 2 – (+1,-1,+1,-1,+1,-1,+1,-1).
# Не забываем повторять шаги задания 1:
- ключевые характеристики датасета

- корреляции
- визуализация на всех парах переменных

[2] На основе созданного в пункте [1] датасета df сгенерировать отдельные
дополнительные датасеты (df_A_B), в которых к классу 0 добавлено A одинаковых точек
с координатами (-B,+B,-B,+B,-B,+B,-B,+B), где A = 1, 10, 100 и B = 1, 10, 100, при этом
количество объектов в остальных классах неизменно.
[3] Выбрать пару классов 0 и 1, и один количественный признак.
Для каждого из датасетов из списка (df, df_A_B) в своем пространстве Х-Y
(количественный признак-класс) построить и визуализировать объекты, линию линейной
регрессии и линию логистической регрессии. Регрессии строить на паре Х-Y(
количественный признак-класс).
Оценить качество работы полученных на основе логистической регрессии
классификаторов, используя ROC кривые, восстановив на графике ROC кривых
определенную логистической регрессией точку классификации Sensitivity-Specificity и
оценные бутстрепом доверительные интервалы CI95 (n=1000).

# Все полученные графики возможно расположить в две колонки: левая колонка –
визуализация пространства и регрессий, правая – графики с ROC кривой и точкой.

[4] Для выбранной пары классов (включая класс с повторенными объектами) на первых
четырех признаках вычислить уравнение множественной линейной регрессии, где Xi –
признаки.
Используя полученное уравнение множественной линейной регрессии, на основе
каждого из датасетов из списка (df, df_A_B) сформировать новые датасеты logdf,
logdf_A_B, в каждом из которых есть только один признак Х, сформированный на основе
соответствующего уравнения множественной линейной регрессии, а переменная Y –
определяет отнесение к классу.
[5] Для каждого из датасетов из списка (logdf, logdf_A_B) в своем пространстве Х-Y
(количественный признак-класс) построить и визуализировать объекты, линию простой
линейной регрессии и линию логистической регрессии. Регрессии строить на паре Х-Y
(количественный признак-класс).
Оценить качество работы полученных на основе логистической регрессии
классификаторов, используя ROC кривые и восстановив на графике ROC кривых
определенную логистической регрессией точку классификации Sensitivity-Specificity и
доверительные интервалы CI95 бутстрепом (n=1000).
# Все полученные графики возможно расположить в две колонки, аналогично пункту [3].

[6] Для выбранной пары классов (включая класс с повторенными объектами),
визуализировать один из датасетов df_A_B на всех парах переменных, построив на
графиках объекты, линии множественной линейной регрессии, разделение классов на
основе логистической регрессии решающей функцией с contour_plot уровнями
классификации c подписанной вероятностью отнесения к целевому классу.
https://stackoverflow.com/questions/20045994/how-do-i-plot-the-decision-boundary-of-a-regression-using-matplotlib
https://inria.github.io/scikit-learn-mooc/python_scripts/logistic_regression.html
https://towardsdatascience.com/probabilistic-logistic-regression-with-tensorflow-73e18f0ddc48/
www.alpha-quantum.com/blog/logistic-regression/logistic-regression-from-scratch/

Задание 4. PCA, tSNE, UMAP, PacMAP
[1] Сгенерировать и визуализировать на парах признаков 5-мерный датасет df из 1000
точек, в котором отдельные точки данных расположены вдоль линии с началом
(0,0,0,0,0) и завершением (+A,+A,+A,+A,+A) с дисперсиями вдоль осей: для оси 1 = A/k,
для оси 2 = A/k, для оси 3 = A/(k*2), для оси 4 = A/(k*4), для оси 5 = A/(k*8), где k может
быть в диапазоне от 4 до 40.
[2] На основе датасета df cгенерировать и визуализировать на парах признаков 5мерные датасеты df_out_i, в которых помимо точек датасета df есть дополнительные
1000 точек с координатой (+A*i,- A*i,+ A*i,- A*i,+ A*i) при i = 1, 2, 5, 10.
[3] Используя метод главных компонент (основанный на корреляциях), для каждого
датасета (df и df_out_i) отдельно визуализировать:
- Scree plot;
- Отображения отдельных объектов-строк в двумерных пространствах всех пар главных
компонент, без отображения старых векторов-переменных;
- Отображения отдельных объектов-строк в двумерных пространствах всех пар главных
компонент, с отображением старых векторов-переменных;
- Отображения степени корреляции старых векторов-переменных с новыми векторамипеременными в двумерных пространствах всех пар главных компонет.
[4] Используя методы UMAP, PacMAP и tSNE, для каждого датасета (df и df_out_i)
отдельно визуализировать проекции c нескольких (не менее 4) рендом-стартов, а также
после предвращения датасетов методом PCA.
[5] Сгенерировать и визуализировать на парах признаков 4-мерный датасет df_LDA из
двух классов (каждый размером 1000 точек), в котором отдельные точки данных первого
класса расположены вдоль линии с началом (0,0,0,0) и завершением (+A,+A,+A,+A),
отдельные точки данных второго класса расположены вдоль линии с началом
(+A/100,0,0,0) и завершением (+A+A/100,+A,+A,+A), с дисперсиями для каждого класса
вдоль осей A/200000.
[6] Используя метод главных компонент (основанный на корреляциях), для датасета
df_LDA из пункта [5] выполнить визуализации аналогично подпунктам пункта [3].
[7] Используя метод LDA, для датасета df_LDA из пункта [5] выполнить визуализации
решения LDA на всех парах переменных.
[8] Взять с Kaggle датасет, в котором есть >=10 переменных, >=10000 объектов и
несколько классов.
[9] Используя метод главных компонент (основанный на корреляциях), для датасета из
пункта [8] определить различными способами (метод Кайзера, метод ломанной трости),
сколько компонент необходимо оставлять для регрессионной модели.
[10] Используя метод главных компонент (основанный на корреляциях), для датасета из
пункта [8] выполнить визуализации аналогично подпунктам пункта [3], с учетом числа
отобранных компонент.
[11] Используя методы UMAP, PacMAP и tSNE, для датасета из пункта [8] отдельно
визуализировать проекции c нескольких (не менее 2) рендом-стартов, а также после
предвращения датасетов методом PCA.
https://umap-learn.readthedocs.io/en/latest/
https://github.com/YingfanWang/PaCMAP

